# IMDb Analytics Pipeline with Airflow & dbt

[![Airflow](https://img.shields.io/badge/Airflow-2.7-red)](https://airflow.apache.org/)
[![dbt](https://img.shields.io/badge/dbt-1.4.6-purple)](https://www.getdbt.com/)
[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-13-blue)](https://www.postgresql.org/)
[![Astronomer](https://img.shields.io/badge/Astro_Runtime-13.0.0-orange)](https://www.astronomer.io/)
[![Cosmos](https://img.shields.io/badge/Cosmos-1.1.1-green)](https://github.com/astronomer/astronomer-cosmos)
[![Status](https://img.shields.io/badge/Status-Production_Ready-brightgreen)]()

## ğŸ“Š Project Overview

A production-ready data pipeline that processes IMDb datasets using modern data engineering best practices. This project demonstrates enterprise-grade ELT (Extract, Load, Transform) architecture with intelligent caching, advanced error handling, and automated data transformations.

**Key Technologies:**
- **Apache Airflow (2.7)**: Pipeline orchestration with Astronomer Runtime
- **dbt (1.4.6)**: Data transformations and modeling framework  
- **Astronomer Cosmos (1.1.1)**: Seamless Airflow â†” dbt integration
- **PostgreSQL (13)**: High-performance data warehouse
- **Docker**: Containerized development environment

**Pipeline Features:**
- **Smart Caching**: HTTP Last-Modified validation and Airflow Variables-based caching
- **Bulk Loading**: PostgreSQL COPY operations for 10-100x faster data loading
- **Layer-based Transformations**: Staging â†’ Intermediate â†’ Marts architecture
- **Production-grade Error Handling**: Exponential backoff, configurable retries, comprehensive logging
- **Intelligent Monitoring**: Task-specific timeouts based on empirical data, heartbeat updates

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   IMDb Datasets  â”‚    â”‚    Airflow DAG      â”‚    â”‚     PostgreSQL       â”‚
â”‚                  â”‚    â”‚                     â”‚    â”‚                      â”‚
â”‚ â€¢ title.basics   â”‚â”€â”€â”€â–ºâ”‚ 1. Download Phase   â”‚â”€â”€â”€â–ºâ”‚ Raw Tables          â”‚
â”‚ â€¢ title.ratings  â”‚    â”‚    - Cache validationâ”‚    â”‚ â€¢ imdb_title_basics â”‚
â”‚ â€¢ name.basics    â”‚    â”‚    - Smart downloads â”‚    â”‚ â€¢ imdb_title_ratingsâ”‚
â”‚ â€¢ title.crew     â”‚    â”‚                     â”‚    â”‚ â€¢ imdb_name_basics  â”‚
â”‚ â€¢ title.episode  â”‚    â”‚ 2. Load Phase       â”‚    â”‚ â€¢ ...               â”‚
â”‚ â€¢ title.akas     â”‚    â”‚    - Bulk COPY ops  â”‚    â”‚                      â”‚
â”‚ â€¢ title.principalsâ”‚    â”‚    - Duplicate prev â”‚    â”‚                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚                           â”‚
                                   â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”             â”‚                 â”‚
                        â”‚   Cosmos Integration   â”‚             â”‚                 â”‚
                        â”‚  (dbt â†” Airflow)      â”‚             â”‚                 â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚                 â”‚
                                   â”‚                           â”‚                 â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚                 â”‚
              â”‚            dbt Transformations          â”‚      â”‚                 â”‚
              â”‚                                         â”‚      â”‚                 â”‚
              â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚      â”‚                 â”‚
              â”‚ â”‚   Staging   â”‚ â”‚   Intermediate   â”‚   â”‚      â”‚                 â”‚
              â”‚ â”‚             â”‚ â”‚                  â”‚   â”‚      â”‚                 â”‚
              â”‚ â”‚ â€¢ Data      â”‚ â”‚ â€¢ Business       â”‚   â”‚      â”‚                 â”‚
              â”‚ â”‚   cleaning  â”‚ â”‚   logic          â”‚   â”‚      â”‚                 â”‚
              â”‚ â”‚ â€¢ Standards â”‚ â”‚ â€¢ Calculations   â”‚   â”‚      â”‚                 â”‚
              â”‚ â”‚ â€¢ Parsing   â”‚ â”‚ â€¢ Joins          â”‚   â”‚      â”‚                 â”‚
              â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚      â”‚                 â”‚
              â”‚                         â”‚              â”‚      â”‚                 â”‚
              â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚      â”‚                 â”‚
              â”‚ â”‚            Marts                    â”‚â”‚      â”‚                 â”‚
              â”‚ â”‚                                     â”‚â”‚      â”‚                 â”‚
              â”‚ â”‚ â€¢ mart_top_titles                   â”‚â”‚      â”‚                 â”‚
              â”‚ â”‚ â€¢ mart_person_career                â”‚â”‚      â”‚                 â”‚
              â”‚ â”‚ â€¢ mart_genre_analytics              â”‚â”‚      â”‚                 â”‚
              â”‚ â”‚ â€¢ mart_series_analytics             â”‚â”‚      â”‚                 â”‚
              â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚      â”‚                 â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚                 â”‚
                                   â”‚                           â”‚                 â”‚
                                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          Analytics Layer                                       â”‚
â”‚                                                                                â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚ â”‚   Top Titles     â”‚ â”‚  Person Career   â”‚ â”‚ Genre Analytics  â”‚               â”‚
â”‚ â”‚                  â”‚ â”‚                  â”‚ â”‚                  â”‚               â”‚
â”‚ â”‚ â€¢ High ratings   â”‚ â”‚ â€¢ Filmography    â”‚ â”‚ â€¢ Trends         â”‚               â”‚
â”‚ â”‚ â€¢ Vote counts    â”‚ â”‚ â€¢ Career spans   â”‚ â”‚ â€¢ Popularity     â”‚               â”‚
â”‚ â”‚ â€¢ Genre analysis â”‚ â”‚ â€¢ Achievements   â”‚ â”‚ â€¢ Time series    â”‚               â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Prerequisites

- **Docker Desktop** (Windows/Mac) or **Docker Engine** (Linux) with Docker Compose
- **Astronomer CLI** (`astro`) - [Installation Guide](https://docs.astronomer.io/astro/cli/install-cli)
- **Minimum 4GB free disk space** for IMDb datasets (compressed: ~1GB, extracted: ~3GB)
- **Git** for version control

### Environment Setup

1. **Clone the repository**
   ```powershell
   git clone <repository-url>
   cd apache-airflow-dev-server
   ```

2. **Initialize Astro project** (if not already done)
   ```powershell
   astro dev init
   ```

3. **Start the complete environment**
   ```powershell
   astro dev start
   ```

   This command initializes:
   - ğŸŒ **Airflow Webserver**: http://localhost:8080 (admin/admin)
   - ğŸ”„ **Airflow Scheduler**: Background task scheduling
   - ğŸ—„ï¸ **PostgreSQL Database**: localhost:5433 (postgres/postgres)
   - ğŸ“Š **Postgres Admin UI**: http://localhost:5050 (admin@admin.com/admin)

### Port Configuration

If ports are already in use, configure alternatives before starting:

```powershell
# Configure custom ports
astro config set webserver.port 8081
astro config set postgres.port 5434

# Apply configuration
astro dev start
```

### dbt Manifest Generation

**âš ï¸ Critical Step**: Cosmos requires a dbt manifest file for optimal performance.

```powershell
# Navigate to dbt project
cd dags/dbt

# Install dbt dependencies
dbt deps

# Generate manifest (required for Cosmos)
dbt parse

# Return to project root
cd ../..
```

**When to regenerate manifest:**
- After adding/modifying dbt models
- After changing dbt project configuration
- Before deploying to production

### Pipeline Execution

1. **Access Airflow UI**: http://localhost:8080 (admin/admin)

2. **Enable the main DAG**:
   - Navigate to DAGs page
   - Find `imdb_cosmos_pipeline`
   - Toggle the DAG to **ON**

3. **Trigger the pipeline**:
   - Click the play button (â–¶ï¸) to trigger manually
   - Or wait for the daily schedule (`@daily`)

4. **Monitor execution**:
   - Download tasks: ~10-30 minutes (depends on internet speed)
   - Load tasks: ~20-60 minutes (depends on system resources) 
   - dbt transformations: ~5-15 minutes

### Verify Installation

```powershell
# Check Airflow status
astro dev ps

# View logs
astro dev logs

# Connect to PostgreSQL
psql -h localhost -p 5433 -U postgres -d airflow
```

## ğŸ“‹ Project Components

### 1. Unified Data Pipeline (`imdb_cosmos_pipeline`)

**Current Implementation**: Single, production-ready DAG that handles the complete ELT process:

- **Download Tasks** (7 parallel tasks):
  - Smart caching with HTTP Last-Modified validation
  - Exponential backoff retry logic for network resilience
  - Automatic file validation and atomic writes

- **Load Tasks** (7 parallel tasks):
  - PostgreSQL COPY operations for high-performance bulk loading
  - Cache-based duplicate prevention
  - Memory-efficient streaming decompression
  - Comprehensive data integrity validation

- **dbt Transformation Groups** (3 sequential groups):
  - **Staging Layer**: Data cleaning and standardization (7 models)
  - **Intermediate Layer**: Business logic and calculated fields (5 models)
  - **Marts Layer**: Analytics-ready tables (4 marts)

### 2. Astronomer Cosmos Integration

**Advanced dbt â†” Airflow Bridge:**

- âœ… **Automatic Task Generation**: Creates Airflow tasks directly from dbt models
- âœ… **Dependency Management**: Preserves dbt model dependencies in Airflow task graph
- âœ… **Layer-based Execution**: Separate task groups for staging/intermediate/marts
- âœ… **Unified Monitoring**: View dbt runs and tests directly in Airflow UI
- âœ… **Intelligent Failure Handling**: Leverages Airflow's retry and alerting for dbt jobs
- âœ… **Performance Optimization**: Uses `LoadMode.DBT_MANIFEST` for faster parsing

**Configuration Highlights:**
```python
# Staging layer (7 models)
stg_render_config = RenderConfig(
    select=["tag:staging"],
    test_behavior=TestBehavior.AFTER_ALL
)

# Intermediate layer (5 models)
int_render_config = RenderConfig(
    select=["tag:intermediate"],
    test_behavior=TestBehavior.AFTER_ALL
)

# Marts layer (4 models)
mart_render_config = RenderConfig(
    select=["tag:marts"],
    test_behavior=TestBehavior.AFTER_ALL
)
```

### 3. dbt Transformation Architecture

**Layer-based Data Modeling** following analytics engineering best practices:

#### ğŸ“¥ **Staging Layer** (Raw Data Processing)
| Model | Purpose | Features |
|-------|---------|----------|
| `stg_title_basics` | Title standardization | Genre parsing, boolean conversion, type casting |
| `stg_name_basics` | Person data cleaning | Profession/filmography array parsing |
| `stg_title_crew_*` | Crew normalization | Director/writer relationship extraction |
| `stg_title_ratings` | Ratings validation | Data quality checks, type conversion |
| `stg_title_episode` | Episode hierarchy | Season/episode number standardization |
| `stg_title_principals` | Cast/crew staging | Role and character data cleaning |

#### âš™ï¸ **Intermediate Layer** (Business Logic)
| Model | Purpose | Dependencies |
|-------|---------|--------------|
| `int_title_with_ratings` | Enriched title data | `stg_title_basics` + `stg_title_ratings` |
| `int_title_with_genres` | Genre dimensional modeling | `stg_title_basics` |
| `int_person_filmography` | Comprehensive career data | Multiple staging models |
| `int_title_hierarchies` | Series-episode relationships | `stg_title_episode` + `stg_title_basics` |
| `int_title_complete` | Fully denormalized titles | All staging models |

#### ğŸ“Š **Marts Layer** (Analytics-Ready)
| Mart | Analytics Focus | Key Metrics |
|------|----------------|-------------|
| `mart_top_titles` | Performance rankings | Ratings, vote counts, genre analysis |
| `mart_person_career` | Individual achievements | Career spans, film counts, role diversity |
| `mart_genre_analytics` | Genre trends | Decade analysis, popularity shifts |
| `mart_series_analytics` | TV series insights | Episode ratings, season performance |

### 4. Production Features

**Enterprise-grade Capabilities:**

- ğŸ”„ **Smart Caching**: Airflow Variables-based persistence across runs
- ğŸ“ˆ **Adaptive Timeouts**: Task-specific timeouts based on empirical data
- ğŸ›¡ï¸ **Error Resilience**: Exponential backoff, configurable retry strategies
- ğŸ“Š **Comprehensive Monitoring**: Heartbeat updates, progress tracking
- ğŸ§¹ **Automatic Cleanup**: Memory management, temporary file removal
- ğŸ”’ **Security**: SQL injection prevention, input validation
- âš¡ **Performance**: Bulk COPY operations, streaming processing

## ğŸ› ï¸ Project Structure

```
apache-airflow-dev-server/                 # Astronomer Astro Project
â”œâ”€â”€ ğŸš€ dags/                               # Airflow DAGs Directory
â”‚   â”œâ”€â”€ download_uploading.py                  # ğŸ¯ MAIN PIPELINE (Production-ready)
â”‚   â”‚                                          #    â”œâ”€ Download tasks (7 parallel)
â”‚   â”‚                                          #    â”œâ”€ Load tasks (7 parallel) 
â”‚   â”‚                                          #    â””â”€ dbt transformation groups (3 layers)
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“Š dbt/                            # dbt Transformation Project  
â”‚       â”œâ”€â”€ models/                            # ğŸ“ˆ 16 Total Models
â”‚       â”‚   â”œâ”€â”€ staging/                           # ğŸ§¹ 7 Staging Models
â”‚       â”‚   â”‚   â”œâ”€â”€ stg_title_basics.sql               # Title standardization & genre parsing
â”‚       â”‚   â”‚   â”œâ”€â”€ stg_name_basics.sql                # Person data with profession arrays
â”‚       â”‚   â”‚   â”œâ”€â”€ stg_title_crew_directors.sql       # Normalized director relationships 
â”‚       â”‚   â”‚   â”œâ”€â”€ stg_title_crew_writers.sql         # Normalized writer relationships
â”‚       â”‚   â”‚   â”œâ”€â”€ stg_title_episode.sql              # TV episode hierarchy cleaning
â”‚       â”‚   â”‚   â”œâ”€â”€ stg_title_principals.sql           # Cast & crew standardization
â”‚       â”‚   â”‚   â”œâ”€â”€ stg_title_ratings.sql              # Ratings validation & typing
â”‚       â”‚   â”‚   â”œâ”€â”€ schema.yml                         # Model tests & documentation
â”‚       â”‚   â”‚   â””â”€â”€ sources.yml                        # Source definitions & freshness
â”‚       â”‚   â”‚
â”‚       â”‚   â”œâ”€â”€ intermediate/                      # âš™ï¸ 5 Intermediate Models  
â”‚       â”‚   â”‚   â”œâ”€â”€ int_title_with_ratings.sql         # Titles + ratings enrichment
â”‚       â”‚   â”‚   â”œâ”€â”€ int_title_with_genres.sql          # Genre dimension modeling
â”‚       â”‚   â”‚   â”œâ”€â”€ int_person_filmography.sql         # Comprehensive career data
â”‚       â”‚   â”‚   â”œâ”€â”€ int_title_hierarchies.sql          # Series-episode relationships
â”‚       â”‚   â”‚   â”œâ”€â”€ int_title_complete.sql             # Fully denormalized titles
â”‚       â”‚   â”‚   â””â”€â”€ schema.yml                         # Relationship tests & docs
â”‚       â”‚   â”‚
â”‚       â”‚   â””â”€â”€ marts/                             # ğŸ“Š 4 Analytics-Ready Marts
â”‚       â”‚       â”œâ”€â”€ mart_top_titles.sql                # Performance & ranking analytics
â”‚       â”‚       â”œâ”€â”€ mart_person_career.sql             # Individual achievement metrics
â”‚       â”‚       â”œâ”€â”€ mart_genre_analytics.sql           # Genre trends & time series
â”‚       â”‚       â”œâ”€â”€ mart_series_analytics.sql          # TV series & episode insights  
â”‚       â”‚       â””â”€â”€ schema.yml                         # Business metric documentation
â”‚       â”‚
â”‚       â”œâ”€â”€ target/                            # ğŸ¯ Compiled dbt Assets
â”‚       â”‚   â”œâ”€â”€ manifest.json                      # ğŸ”— Model dependencies (for Cosmos)
â”‚       â”‚   â”œâ”€â”€ run_results.json                   # âœ… Execution results & performance
â”‚       â”‚   â””â”€â”€ compiled/                          # ğŸ“„ Generated SQL for review
â”‚       â”‚
â”‚       â”œâ”€â”€ dbt_packages/                      # ğŸ“¦ External Dependencies
â”‚       â”‚   â””â”€â”€ dbt_utils/                         # ğŸ› ï¸ dbt community utilities
â”‚       â”‚
â”‚       â”œâ”€â”€ dbt_project.yml                   # âš™ï¸ Project configuration & materialization
â”‚       â”œâ”€â”€ profiles.yml                      # ğŸ”Œ Database connection profiles (port 5433)
â”‚       â”œâ”€â”€ packages.yml                      # ğŸ“‹ Package dependencies (dbt-utils)
â”‚       â””â”€â”€ README.md                         # ğŸ“š Detailed dbt documentation
â”‚
â”œâ”€â”€ ğŸ“ Data Directories/                       # Local Storage (auto-created)
â”‚   â”œâ”€â”€ imdb_data/                                # ğŸ’¾ Downloaded datasets (.tsv.gz files)
â”‚   â””â”€â”€ imdb_schemas/                             # ğŸ—‚ï¸ PostgreSQL table schemas (.sql files)
â”‚
â”œâ”€â”€ ğŸ³ Docker Configuration/                   # Containerization Setup
â”‚   â”œâ”€â”€ Dockerfile                                # ğŸ—ï¸ Astro Runtime 13.0.0 (Airflow 2.7)
â”‚   â”œâ”€â”€ docker-compose.override.yml               # ğŸ”§ PostgreSQL 13 configuration
â”‚   â””â”€â”€ .env                                      # ğŸŒ Environment variables
â”‚
â”œâ”€â”€ ğŸ“‹ Configuration Files/                    # Project Setup
â”‚   â”œâ”€â”€ requirements.txt                          # ğŸ Python dependencies
â”‚   â”‚                                             #    â”œâ”€ dbt-core==1.4.6
â”‚   â”‚                                             #    â”œâ”€ dbt-postgres==1.4.6  
â”‚   â”‚                                             #    â””â”€ astronomer-cosmos==1.1.1
â”‚   â”œâ”€â”€ packages.txt                              # ğŸ“¦ System packages
â”‚   â”œâ”€â”€ airflow_settings.yaml                    # âš™ï¸ Airflow connection configs
â”‚   â””â”€â”€ README.md                                 # ğŸ“– This documentation
â”‚
â””â”€â”€ ğŸ§ª Testing/                               # Quality Assurance  
    â””â”€â”€ tests/dags/                               # ğŸ” DAG validation tests
        â””â”€â”€ test_dag_example.py                       # âœ… Basic DAG import testing
```

### Key Directory Functions

| Directory | Purpose | Auto-generated |
|-----------|---------|----------------|
| `dags/` | Airflow DAGs and dbt project | Partial (dbt target/) |
| `imdb_data/` | Downloaded IMDb datasets | âœ… Yes |
| `imdb_schemas/` | PostgreSQL table definitions | âŒ Manual |
| `dbt/target/` | Compiled dbt artifacts | âœ… Yes (dbt parse) |
| `dbt/dbt_packages/` | External dbt packages | âœ… Yes (dbt deps) |

### Critical Files

| File | Purpose | Update Frequency |
|------|---------|------------------|
| `download_uploading.py` | Main production pipeline | As needed |
| `dbt/manifest.json` | Cosmos dependency mapping | After model changes |
| `dbt/profiles.yml` | Database connections | Environment changes |
| `requirements.txt` | Python dependencies | Version updates |

## ğŸ“š Usage Guide

### Production Pipeline Execution

#### ğŸ¯ Primary Workflow: `imdb_cosmos_pipeline`

**Single DAG handles complete ELT process:**

1. **Navigate to Airflow UI**: http://localhost:8080 (admin/admin)

2. **Enable the pipeline**:
   ```
   DAGs â†’ imdb_cosmos_pipeline â†’ Toggle ON
   ```

3. **Monitor execution phases**:
   ```
   Phase 1: Download Tasks    (7 parallel) â†’  ~10-30 min
   Phase 2: Load Tasks        (7 parallel) â†’  ~20-60 min  
   Phase 3: dbt Staging       (7 models)   â†’  ~2-5 min
   Phase 4: dbt Intermediate  (5 models)   â†’  ~2-5 min
   Phase 5: dbt Marts         (4 models)   â†’  ~1-3 min
   ```

4. **Execution results**:
   - Raw data: 7 PostgreSQL tables (`imdb_*`)
   - Staging views: 7 cleaned datasets (`stg_*`)
   - Intermediate views: 5 business logic models (`int_*`)
   - Marts tables: 4 analytics-ready datasets (`mart_*`)

### Manual dbt Operations

```powershell
# Navigate to dbt project
cd dags/dbt

# ğŸ”„ Core Operations
dbt deps                      # Install packages
dbt parse                     # Generate manifest for Cosmos
dbt run --profiles-dir .      # Run all models

# ğŸ¯ Layer-specific Execution
dbt run --profiles-dir . --select tag:staging       # Staging only
dbt run --profiles-dir . --select tag:intermediate  # Intermediate only  
dbt run --profiles-dir . --select tag:marts         # Marts only

# ğŸ§ª Testing & Validation
dbt test --profiles-dir .                           # Run all tests
dbt test --profiles-dir . --select staging.*        # Test staging models
dbt test --profiles-dir . --select source:*         # Test source data

# ğŸ“Š Documentation & Analysis
dbt docs generate --profiles-dir .                  # Generate docs
dbt docs serve --profiles-dir .                     # Serve locally (port 8080)
dbt ls --profiles-dir . --select +mart_top_titles   # Show dependencies
```

### Database Access

```powershell
# PostgreSQL Connection
psql -h localhost -p 5433 -U postgres -d airflow

# Query examples
\dt                           # List all tables
SELECT * FROM mart_top_titles LIMIT 10;
SELECT COUNT(*) FROM imdb_title_basics;
```

### Performance Monitoring

```powershell
# Airflow logs
astro dev logs scheduler      # Scheduler logs
astro dev logs webserver      # Webserver logs  

# Container status
astro dev ps                  # Running containers
astro dev stop                # Stop environment
astro dev start               # Restart environment
```

### Troubleshooting

#### Common Issues & Solutions

| Issue | Symptom | Solution |
|-------|---------|----------|
| **dbt Manifest Missing** | Cosmos parse errors | `cd dags/dbt && dbt parse` |
| **Port Conflicts** | Cannot start containers | Use `astro config set` |
| **Download Failures** | Network timeout errors | Check retry configuration |
| **Database Connection** | Connection refused | Verify port 5433 is free |
| **Memory Issues** | Tasks killed by OS | Increase Docker memory limit |

#### Debug Commands

```powershell
# dbt debugging
cd dags/dbt
dbt debug --profiles-dir .    # Test database connection

# Airflow task debugging  
astro dev bash               # Enter container
airflow tasks test <dag_id> <task_id> <date>

# Clean restart
astro dev kill               # Force stop
docker system prune -f       # Clean Docker cache
astro dev start              # Fresh start
```

### Environment Management

```powershell
# Development workflow
astro dev start              # Start development
# ... make changes ...
astro dev restart            # Apply changes
dbt parse                    # Update manifest after dbt changes

# Production deployment
astro deploy                 # Deploy to Astronomer (if configured)
```

### Data Pipeline Monitoring

**Key Metrics to Monitor:**
- **Download Cache Hit Rate**: Check Airflow Variables
- **Load Performance**: Row counts vs. file sizes
- **dbt Test Results**: Data quality validation
- **Task Duration Trends**: Performance over time

## ğŸ§© Data Models & Analytics

### Source Data Overview

**IMDb Dataset Statistics:**
| Dataset | Records | Size (Compressed) | Primary Use |
|---------|---------|-------------------|-------------|
| `title.basics.tsv.gz` | ~10M | ~200MB | Core title information |
| `title.principals.tsv.gz` | ~57M | ~600MB | Cast and crew roles |
| `title.akas.tsv.gz` | ~35M | ~300MB | International titles |
| `name.basics.tsv.gz` | ~13M | ~150MB | Person information |
| `title.crew.tsv.gz` | ~10M | ~100MB | Directors and writers |
| `title.episode.tsv.gz` | ~7.8M | ~80MB | TV episode hierarchy |
| `title.ratings.tsv.gz` | ~1.4M | ~25MB | User ratings |

### Analytics Capabilities

#### ğŸ“Š **Available Marts**

| Mart | Analytics Focus | Key Questions Answered |
|------|----------------|------------------------|
| **`mart_top_titles`** | Performance & Rankings | â€¢ What are the highest-rated films by genre?<br>â€¢ Which titles have the most votes?<br>â€¢ How do ratings vary by release decade? |
| **`mart_person_career`** | Individual Achievements | â€¢ Who are the most prolific directors?<br>â€¢ Which actors have the longest careers?<br>â€¢ What's the average career span by profession? |
| **`mart_genre_analytics`** | Genre Trends | â€¢ How have genre preferences changed over time?<br>â€¢ Which genres consistently rate highest?<br>â€¢ What's the volume trend by genre and decade? |
| **`mart_series_analytics`** | TV Series Insights | â€¢ Which series have the most consistent ratings?<br>â€¢ How do episode ratings vary within seasons?<br>â€¢ What's the average series length by genre? |

#### ğŸ” **Sample Analytics Queries**

```sql
-- Top 10 highest-rated movies with 10k+ votes
SELECT title, average_rating, num_votes, primary_genre
FROM mart_top_titles 
WHERE title_type = 'movie' AND num_votes >= 10000
ORDER BY average_rating DESC, num_votes DESC
LIMIT 10;

-- Director career analysis
SELECT primary_name, total_titles, career_span_years, avg_rating
FROM mart_person_career 
WHERE primary_profession = 'director' AND total_titles >= 5
ORDER BY avg_rating DESC, total_titles DESC;

-- Genre popularity by decade
SELECT decade, genre, title_count, avg_rating 
FROM mart_genre_analytics
WHERE decade >= 2000
ORDER BY decade DESC, title_count DESC;

-- TV series with most consistent ratings
SELECT series_title, total_episodes, avg_rating, rating_std_dev
FROM mart_series_analytics
WHERE total_episodes >= 10
ORDER BY rating_std_dev ASC, avg_rating DESC;
```

### Advanced dbt Features

**ğŸ¯ Model Tagging Strategy:**
```sql
-- Staging models
{{ config(tags=['staging']) }}

-- Intermediate models  
{{ config(tags=['intermediate']) }}

-- Marts models
{{ config(tags=['marts']) }}
```

**ğŸ“Š Materialization Strategy:**
- **Staging/Intermediate**: `VIEW` (fast, always fresh)
- **Marts**: `TABLE` (performance for analytics)

**ğŸ§ª Comprehensive Testing:**
- **Data Quality**: `not_null`, `unique`, `accepted_values`
- **Relationships**: `relationships` tests between models
- **Business Logic**: Custom tests for derived fields
- **Source Freshness**: Validation of data currency

For detailed model documentation and lineage, refer to:
- [dbt Project README](./dags/dbt/README.md)
- dbt docs site: `cd dags/dbt && dbt docs serve --profiles-dir .`

## ğŸ“ Development & Deployment

### Future Enhancements

**ğŸ”„ Pipeline Improvements:**
- [ ] **Incremental Loading**: Implement incremental models for large datasets
- [ ] **Data Quality Monitoring**: Advanced anomaly detection and alerting
- [ ] **Performance Optimization**: Parallel dbt execution and resource allocation
- [ ] **Schema Evolution**: Automatic handling of IMDb schema changes

**ğŸ“Š Analytics Extensions:**
- [ ] **Real-time Dashboards**: Integration with Superset or Metabase
- [ ] **Machine Learning Models**: Rating prediction and recommendation engines
- [ ] **API Layer**: REST API for analytics data consumption
- [ ] **Data Exports**: Automated report generation and distribution

**ğŸš€ Production Features:**
- [ ] **Multi-environment Support**: Dev/Staging/Production configuration
- [ ] **CI/CD Pipeline**: Automated testing and deployment
- [ ] **Monitoring & Alerting**: Comprehensive observability stack
- [ ] **Data Lineage**: Visual impact analysis and documentation

### Contributing Guidelines

**Development Workflow:**
1. **Fork the repository** and create a feature branch
2. **Update dbt manifest** after model changes: `dbt parse`
3. **Run comprehensive tests**: `dbt test --profiles-dir .`
4. **Validate DAG syntax**: `astro dev parse`
5. **Update documentation** for significant changes
6. **Submit pull request** with detailed description

**Code Standards:**
- **dbt Models**: Follow naming conventions (`stg_*`, `int_*`, `mart_*`)
- **SQL Formatting**: Use consistent indentation and commenting
- **Documentation**: Update `schema.yml` files for new models
- **Testing**: Add appropriate tests for data quality validation

### Production Deployment

**Astronomer Platform:**
```powershell
# Initialize Astronomer deployment
astro login
astro deployment create --name imdb-production

# Deploy to production
astro deploy --deployment-id <deployment-id>
```

**Environment Configuration:**
```yaml
# astro.yaml example
project:
  name: imdb-analytics-pipeline
environments:
  development:
    dag_deploy_enabled: true
  production:
    dag_deploy_enabled: true
    webserver:
      replicas: 2
    scheduler:
      replicas: 2
```

## ğŸ”— Resources & Documentation

### ğŸ“š **Official Documentation**
- [Apache Airflow Docs](https://airflow.apache.org/docs/) - Core orchestration platform
- [dbt Documentation](https://docs.getdbt.com/) - Transformation framework
- [Astronomer Cosmos](https://astronomer.github.io/astronomer-cosmos/) - Airflow â†” dbt integration
- [Astronomer Platform](https://www.astronomer.io/docs/astro/) - Managed Airflow service

### ğŸ› ï¸ **Technical References**
- [IMDb Dataset Interface](https://www.imdb.com/interfaces/) - Source data documentation
- [PostgreSQL Documentation](https://www.postgresql.org/docs/) - Database platform
- [Docker Documentation](https://docs.docker.com/) - Containerization

### ğŸ“– **Learning Resources**
- [Analytics Engineering Guide](https://www.getdbt.com/analytics-engineering/) - Best practices
- [Airflow Best Practices](https://airflow.apache.org/docs/apache-airflow/stable/best-practices.html) - Production guidelines
- [Modern Data Stack](https://www.getdbt.com/blog/future-of-the-modern-data-stack/) - Architecture principles

### ğŸ¤ **Community & Support**
- [dbt Community](https://www.getdbt.com/community/) - Slack workspace and forums
- [Airflow Community](https://airflow.apache.org/community/) - Mailing lists and events
- [Astronomer Community](https://www.astronomer.io/community/) - Support and resources

---

## ğŸ“„ License & Credits

**Project Information:**
- **Author**: Andrea Usai
- **Version**: 2.0.0 (Production Ready)
- **Last Updated**: January 2025
- **License**: [Specify your license]

**Acknowledgments:**
- **IMDb**: For providing comprehensive entertainment datasets
- **Astronomer**: For the excellent Cosmos integration and Astro platform
- **dbt Labs**: For the powerful data transformation framework
- **Apache Airflow Community**: For the robust orchestration platform

**Data Source Attribution:**
> Information courtesy of IMDb (https://www.imdb.com). Used with permission.

---

**â­ If this project helped you, please consider giving it a star on GitHub!**
